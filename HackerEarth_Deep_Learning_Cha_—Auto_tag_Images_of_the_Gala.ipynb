{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HackerEarth Deep Learning Cha...—Auto-tag Images of the Gala.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPaIecZ7zxGplXUtuMB5sRd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashwanidv100/Data-Analysis-Task/blob/master/HackerEarth_Deep_Learning_Cha_%E2%80%94Auto_tag_Images_of_the_Gala.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9arZdHtfzhGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from tqdm import tqdm \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylcrACyU0kJL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "989ee076-f075-4936-dd01-4b5f8e1d036a"
      },
      "source": [
        "train = pd.read_csv('/content/dataset/train.csv')\n",
        "test = pd.read_csv('/content/dataset/test.csv')\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image7042.jpg</td>\n",
              "      <td>Food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image3327.jpg</td>\n",
              "      <td>misc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image10335.jpg</td>\n",
              "      <td>Attire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image8019.jpg</td>\n",
              "      <td>Food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image2128.jpg</td>\n",
              "      <td>Attire</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Image   Class\n",
              "0   image7042.jpg    Food\n",
              "1   image3327.jpg    misc\n",
              "2  image10335.jpg  Attire\n",
              "3   image8019.jpg    Food\n",
              "4   image2128.jpg  Attire"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8NNWDYj1nPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Class_map = {'Food':0, 'Attire':1, 'Decorationandsignage':2, 'misc':3}\n",
        "inverse_map = {0:'Food', 1:'Attire', 2:'Decorationandsignage', 3:'misc'}\n",
        "train['Class'] = train['Class'].map(Class_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsUdGl1P3UKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "9faafb2a-f5b3-4066-c432-a9ce6d655d5e"
      },
      "source": [
        "train['Class']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       3\n",
              "2       1\n",
              "3       0\n",
              "4       1\n",
              "       ..\n",
              "5978    0\n",
              "5979    1\n",
              "5980    0\n",
              "5981    0\n",
              "5982    1\n",
              "Name: Class, Length: 5983, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsJmhV70PzsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7c3a29d-66a6-4e93-e205-4c7efb58cc1c"
      },
      "source": [
        "train_img = []\n",
        "train_label = []\n",
        "j=0\n",
        "path = '/content/dataset/Train Images'\n",
        "for i in tqdm(train['Image']):\n",
        "  final_path = os.path.join(path,i)\n",
        "  img = cv2.imread(final_path)\n",
        "  img = cv2.resize(img,(150,150))\n",
        "  img = img.astype('float32')\n",
        "  train_img.append(img)\n",
        "  train_label.append(train['Class'][j])\n",
        "  j = j+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5983/5983 [00:02<00:00, 2447.64it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R3yD1PTVvgm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gxYsUrrFRtNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator( featurewise_center=False,  \n",
        "                              samplewise_center=False, \n",
        "                              featurewise_std_normalization=False,  \n",
        "                              samplewise_std_normalization=False, \n",
        "                              zca_whitening=False,  \n",
        "                              rotation_range=10,  \n",
        "                              zoom_range = 0.1,\n",
        "                              width_shift_range=0.2, \n",
        "                              height_shift_range=0.2,  \n",
        "                              horizontal_flip=True,\n",
        "                              vertical_flip=False )\n",
        "\n",
        "datagen.fit(train_img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKZfPJEhV3ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e76fc3de-cf15-4825-8b4f-97ea94d8ea0d"
      },
      "source": [
        "test_img = []\n",
        "path = '/content/dataset/Test Images'\n",
        "for i in tqdm(test['Image']):\n",
        "  final_path = os.path.join(path,i)\n",
        "  img = cv2.imread(final_path)\n",
        "  img = cv2.resize(img, (150,150))\n",
        "  img = img.astype('float32')\n",
        "  test_img.append(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3219/3219 [00:00<00:00, 3770.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoqhL-1JWwbM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6286ac43-8670-4940-b392-86e3f02c3aaa"
      },
      "source": [
        "train_img = np.array(train_img)\n",
        "test_img = np.array(test_img)\n",
        "train_label = np.array(train_label)\n",
        "print(train_img.shape)\n",
        "print(test_img.shape)\n",
        "print(train_label.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5983, 150, 150, 3)\n",
            "(3219, 150, 150, 3)\n",
            "(5983,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPoWH9fWXNvj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "098ebd00-844e-44a1-eeda-c76c2b021eb0"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "from tensorflow.keras.layers import Flatten,Dense,Dropout,BatchNormalization\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVPY8I5tXU3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19793e1c-ab42-40db-bed5-862ca9cb9db1"
      },
      "source": [
        "base_model = VGG16(include_top = False, weights = 'imagenet', input_shape= (150,150,3), pooling = 'avg')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "from keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "reduce_learning_rate = ReduceLROnPlateau( monitor='loss',\n",
        "                                          factor=0.1,\n",
        "                                          patience=2,\n",
        "                                          cooldown=2,\n",
        "                                          min_lr=0.00001,\n",
        "                                          verbose=1 )\n",
        "\n",
        "callbacks = [reduce_learning_rate]\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.fit_generator(datagen.flow(train_img, to_categorical(train_label,4),batch_size= 32), epochs = 30, callbacks = callbacks )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "187/187 [==============================] - 30s 161ms/step - loss: 1.6260 - acc: 0.6398\n",
            "Epoch 2/40\n",
            "187/187 [==============================] - 30s 160ms/step - loss: 0.7539 - acc: 0.7256\n",
            "Epoch 3/40\n",
            "187/187 [==============================] - 30s 162ms/step - loss: 0.5911 - acc: 0.7789\n",
            "Epoch 4/40\n",
            "187/187 [==============================] - 31s 165ms/step - loss: 0.5237 - acc: 0.8061\n",
            "Epoch 5/40\n",
            "187/187 [==============================] - 30s 159ms/step - loss: 0.4640 - acc: 0.8258\n",
            "Epoch 6/40\n",
            "187/187 [==============================] - 30s 159ms/step - loss: 0.4253 - acc: 0.8345\n",
            "Epoch 7/40\n",
            "187/187 [==============================] - 31s 166ms/step - loss: 0.3903 - acc: 0.8521\n",
            "Epoch 8/40\n",
            "187/187 [==============================] - 30s 161ms/step - loss: 0.3652 - acc: 0.8591\n",
            "Epoch 9/40\n",
            "187/187 [==============================] - 30s 162ms/step - loss: 0.3331 - acc: 0.8785\n",
            "Epoch 10/40\n",
            "187/187 [==============================] - 31s 164ms/step - loss: 0.3218 - acc: 0.8748\n",
            "Epoch 11/40\n",
            "187/187 [==============================] - 31s 163ms/step - loss: 0.3071 - acc: 0.8855\n",
            "Epoch 12/40\n",
            "187/187 [==============================] - 29s 157ms/step - loss: 0.2916 - acc: 0.8924\n",
            "Epoch 13/40\n",
            "187/187 [==============================] - 30s 160ms/step - loss: 0.2800 - acc: 0.8975\n",
            "Epoch 14/40\n",
            "187/187 [==============================] - 31s 163ms/step - loss: 0.2711 - acc: 0.8974\n",
            "Epoch 15/40\n",
            "187/187 [==============================] - 30s 159ms/step - loss: 0.2566 - acc: 0.9111\n",
            "Epoch 16/40\n",
            "187/187 [==============================] - 30s 161ms/step - loss: 0.2301 - acc: 0.9184\n",
            "Epoch 17/40\n",
            "187/187 [==============================] - 31s 163ms/step - loss: 0.2284 - acc: 0.9191\n",
            "Epoch 18/40\n",
            "187/187 [==============================] - 30s 161ms/step - loss: 0.2210 - acc: 0.9188\n",
            "Epoch 19/40\n",
            "187/187 [==============================] - 30s 158ms/step - loss: 0.2103 - acc: 0.9223\n",
            "Epoch 20/40\n",
            "187/187 [==============================] - 30s 159ms/step - loss: 0.2161 - acc: 0.9218\n",
            "Epoch 21/40\n",
            "186/187 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9276\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "187/187 [==============================] - 31s 168ms/step - loss: 0.2132 - acc: 0.9271\n",
            "Epoch 22/40\n",
            "187/187 [==============================] - 31s 165ms/step - loss: 0.1631 - acc: 0.9442\n",
            "Epoch 23/40\n",
            "187/187 [==============================] - 30s 161ms/step - loss: 0.1356 - acc: 0.9524\n",
            "Epoch 24/40\n",
            "187/187 [==============================] - 30s 160ms/step - loss: 0.1310 - acc: 0.9547\n",
            "Epoch 25/40\n",
            "187/187 [==============================] - 31s 164ms/step - loss: 0.1300 - acc: 0.9569\n",
            "Epoch 26/40\n",
            "187/187 [==============================] - 31s 165ms/step - loss: 0.1185 - acc: 0.9611\n",
            "Epoch 27/40\n",
            "187/187 [==============================] - 30s 162ms/step - loss: 0.1136 - acc: 0.9597\n",
            "Epoch 28/40\n",
            "187/187 [==============================] - 31s 165ms/step - loss: 0.1187 - acc: 0.9592\n",
            "Epoch 29/40\n",
            "187/187 [==============================] - 31s 164ms/step - loss: 0.1120 - acc: 0.9599\n",
            "Epoch 30/40\n",
            "187/187 [==============================] - 30s 161ms/step - loss: 0.1167 - acc: 0.9577\n",
            "Epoch 31/40\n",
            "187/187 [==============================] - 31s 163ms/step - loss: 0.1058 - acc: 0.9614\n",
            "Epoch 32/40\n",
            "187/187 [==============================] - 31s 163ms/step - loss: 0.1015 - acc: 0.9677\n",
            "Epoch 33/40\n",
            "187/187 [==============================] - 31s 166ms/step - loss: 0.0993 - acc: 0.9661\n",
            "Epoch 34/40\n",
            "187/187 [==============================] - 31s 165ms/step - loss: 0.0951 - acc: 0.9667\n",
            "Epoch 35/40\n",
            "187/187 [==============================] - 31s 167ms/step - loss: 0.0995 - acc: 0.9651\n",
            "Epoch 36/40\n",
            "186/187 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9661\n",
            "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "187/187 [==============================] - 31s 167ms/step - loss: 0.0954 - acc: 0.9659\n",
            "Epoch 37/40\n",
            "187/187 [==============================] - 31s 166ms/step - loss: 0.0873 - acc: 0.9706\n",
            "Epoch 38/40\n",
            "187/187 [==============================] - 31s 166ms/step - loss: 0.0873 - acc: 0.9694\n",
            "Epoch 39/40\n",
            "186/187 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9718\n",
            "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "187/187 [==============================] - 30s 163ms/step - loss: 0.0872 - acc: 0.9718\n",
            "Epoch 40/40\n",
            "187/187 [==============================] - 31s 165ms/step - loss: 0.0864 - acc: 0.9702\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ee8090240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJKvHLWeLxxL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "fb8a4070-452b-43c1-9bdb-b6255a3085ba"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 512)               14714688  \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 4)                 1028      \n",
            "=================================================================\n",
            "Total params: 14,847,044\n",
            "Trainable params: 132,356\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2Qd27PUI3Wv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "571bbc81-8420-4583-ad86-24dfdb1b8472"
      },
      "source": [
        "labels = model.predict(test_img)\n",
        "print(labels[:4])\n",
        "label = [np.argmax(i) for i in labels]\n",
        "class_label = [inverse_map[x] for x in label]\n",
        "print(class_label[:3])\n",
        "submission = pd.DataFrame({ 'Image': test.Image, 'Class': class_label })\n",
        "submission.head(10)\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.6524018e-01 2.9364601e-02 2.9820422e-04 5.0969585e-03]\n",
            " [5.7361704e-01 1.0449989e-05 4.1876619e-06 4.2636830e-01]\n",
            " [9.9993634e-01 1.5673559e-18 2.1077989e-16 6.3607957e-05]\n",
            " [9.9985528e-01 1.7374344e-13 6.5630112e-14 1.4465187e-04]]\n",
            "['Food', 'Food', 'Food']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}